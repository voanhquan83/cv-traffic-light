import os, json, tempfile
import numpy as np
import cv2
import streamlit as st

# ---- import detector (ƒë·∫∑t c√πng th∆∞ m·ª•c) ----
from traffic_light_detection import detect_traffic_light_color, letterbox_resize
st.set_page_config(page_title="Nh·∫≠n di·ªán ƒë√®n giao th√¥ng (local)", page_icon="üö¶", layout="centered")

st.title("üö¶ Nh·∫≠n di·ªán gi√° tr·ªã ƒë√®n giao th√¥ng")
st.caption("Ch·ªçn 1 ·∫£nh ‚Üí ph√¢n t√≠ch m√†u ƒë√®n ƒëang s√°ng, k√®m k·∫øt lu·∫≠n ti·∫øng Vi·ªát")

# Tu·ª≥ ch·ªçn
col1, col2 = st.columns(2)
force_orientation = col1.selectbox("H∆∞·ªõng ƒë√®n", ["T·ª± ph√°t hi·ªán", "√âp ƒë√®n d·ªçc", "√âp ƒë√®n ngang"])
denoise = col2.selectbox("B·ªô l·ªçc nhi·ªÖu", ["bilateral", "nlmeans"])

uploaded = st.file_uploader("Ch·ªçn ·∫£nh (jpg/png/webp/bmp)", type=["jpg","jpeg","png","bmp","webp"])

def vietnamese_conclusion(result: dict) -> str:
    label_vi = {"red":"ƒê√®n ƒê·ªé ƒëang s√°ng", "yellow":"ƒê√®n V√ÄNG ƒëang s√°ng", "green":"ƒê√®n XANH ƒëang s√°ng", "unknown":"Kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c m√†u ƒë√®n"}
    ori_vi = {"vertical":"ƒë√®n d·ªçc", "horizontal":"ƒë√®n ngang"}
    lamps = result.get("lamps", [])
    parts=[]
    for lp in lamps:
        slot=lp.get("slot","")
        slot_vi={"top":"b√≥ng TR√äN","mid":"b√≥ng GI·ªÆA","bot":"b√≥ng D∆Ø·ªöI","left":"b√≥ng TR√ÅI","center":"b√≥ng GI·ªÆA","right":"b√≥ng PH·∫¢I"}.get(slot,slot)
        color_vi={"red":"ƒë·ªè","yellow":"v√†ng","green":"xanh","unknown":"kh√¥ng r√µ"}.get(lp.get("label","unknown"),"kh√¥ng r√µ")
        parts.append(f"{slot_vi}: {color_vi}")
    lamps_text = "; ".join(parts) if parts else "Kh√¥ng ph√°t hi·ªán ƒë·ªß 3 b√≥ng."
    return f"{label_vi.get(result.get('label','unknown'),'Kh√¥ng x√°c ƒë·ªãnh')}. H∆∞·ªõng: {ori_vi.get(result.get('orientation',''),'kh√¥ng r√µ')}. Tr·∫°ng th√°i c√°c b√≥ng: {lamps_text}."

def draw_vis(src_path: str, result: dict) -> np.ndarray:
    img = cv2.imread(src_path)
    vis, _, _ = letterbox_resize(img, (512, 512))
    if result.get("box"):
        x,y,w,h = result["box"]
        cv2.rectangle(vis,(x,y),(x+w,y+h),(0,255,255),2)
    text = f"{result.get('label','unknown')} | {result.get('orientation','?')} ({int(result.get('score',0))})"
    cv2.putText(vis, text, (10,30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,255), 2, cv2.LINE_AA)
    for lp in result.get("lamps", [])[:3]:
        bx,by,bw,bh = lp["box"]
        cv2.rectangle(vis,(bx,by),(bx+bw,by+bh),(0,255,0),2)
        tag = f"{lp['slot']}:{lp['label']}"
        cv2.putText(vis, tag, (bx, max(0,by-6)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0),1,cv2.LINE_AA)
    vis = cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)
    return vis

if uploaded is not None:
    # L∆∞u t·∫°m ƒë·ªÉ OpenCV ƒë·ªçc
    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded.name)[1]) as tmp:
        tmp.write(uploaded.read())
        tmp_path = tmp.name

    st.image(uploaded, caption="·∫¢nh ƒë√£ ch·ªçn", use_container_width=True)

    # Ch·∫°y detect
    result = detect_traffic_light_color(tmp_path, denoise=denoise)
    if force_orientation == "√âp ƒë√®n d·ªçc":
        result["orientation"] = "vertical"
    elif force_orientation == "√âp ƒë√®n ngang":
        result["orientation"] = "horizontal"

    # K·∫øt lu·∫≠n TV
    st.subheader("K·∫øt lu·∫≠n (Ti·∫øng Vi·ªát)")
    st.success(vietnamese_conclusion(result))

    # ·∫¢nh ƒë√£ ƒë√°nh d·∫•u
    st.subheader("·∫¢nh ƒë√£ ƒë√°nh d·∫•u")
    st.image(draw_vis(tmp_path, result), use_container_width=True)

    # JSON k·∫øt qu·∫£
    with st.expander("Xem JSON k·∫øt qu·∫£"):
        st.code(json.dumps(result, ensure_ascii=False, indent=2), language="json")
